{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,itertools,sys,pdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from ultron.factor.genetic.geneticist.genetic import Gentic\n",
    "from ultron.factor.fitness.weighted import Weighted\n",
    "from ultron.factor.genetic.geneticist.operators import calc_factor\n",
    "import multiprocessing\n",
    "from alphamind.data.processing import factor_processing\n",
    "from alphamind.data.standardize import standardize\n",
    "from alphamind.data.winsorize import winsorize_normal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IC 方法\n",
    "def websim_weighted(factor_data, total_data, factor_sets):\n",
    "    factor_data = factor_data.copy()\n",
    "    factor_data = factor_data.reset_index().sort_values(['trade_date','code'])\n",
    "    factor_data = factor_data.fillna(0)\n",
    "    score = np.corrcoef(factor_data['transformed'].values, total_data.sort_values(\n",
    "        ['trade_date','code'])['ret'].values)[0,1]\n",
    "    return abs(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## websim 方法\n",
    "def websim_weighted(factor_data, total_data, factor_sets):\n",
    "    factor_data = factor_data.copy()\n",
    "    risk_data = total_data[['trade_date','code'] + industry_styles + ['SIZE']]\n",
    "    forward_returns = total_data[['trade_date','code','ret']]\n",
    "    weight = Weighted.create_weighted(method='onlylong')()\n",
    "    stats = weight.run(factor_data=factor_data.reset_index(), \n",
    "                       risk_data=risk_data, forward_returns=forward_returns,\n",
    "                       factor_name='transformed',horizon=5,default_value=np.iinfo(np.int32).min)\n",
    "    if abs(stats['fitness']) > 0.554246 and stats['sharpe'] > 1.243449:\n",
    "        score = abs(stats['fitness'])\n",
    "    else:\n",
    "        score = abs(stats['fitness']) / 100\n",
    "    return abs(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_rate(params):\n",
    "    name = params['name']\n",
    "    data = params['data']\n",
    "    coverage_rate  =  1 - np.isnan(data).sum()/ len(data)\n",
    "    return {'rate':coverage_rate,'name':name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return winsorized series\n",
    "def se_winsorize(se, method='sigma', limits=(3.0, 3.0), drop=False):\n",
    "    if method == 'quantile':\n",
    "        down, up = se.quantile([limits[0], 1.0 - limits[1]])\n",
    "    elif method == 'sigma':\n",
    "        std, mean = se.std(), se.mean()\n",
    "        down, up = mean - limits[0]*std, mean + limits[1]*std\n",
    "\n",
    "    if drop:\n",
    "        se[se<down] = np.NaN\n",
    "        se[se>up] = np.NaN\n",
    "    else:\n",
    "        se[se<down] = down\n",
    "        se[se>up] = up\n",
    "    return se\n",
    "\n",
    "\n",
    "# return standardized series\n",
    "def se_standardize(se):\n",
    "    try:\n",
    "        res = (se - np.nanmean(se)) / np.nanstd(se)\n",
    "    except:\n",
    "        res = pd.Series(data=np.NaN, index=se.index)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "universe = 'hs300'\n",
    "with open('./' + str(universe) + '_fac_results.pkl','rb') as file2:\n",
    "    fac_results = pickle.load(file2)\n",
    "    \n",
    "with open('./' + str(universe) + '_factor_data.pkl','rb') as file2:\n",
    "    factor_data = pickle.load(file2)\n",
    "\n",
    "with open('./' + str(universe) + '_return_data.pkl','rb') as file2:\n",
    "    return_data = pickle.load(file2)\n",
    "    \n",
    "with open('./' + str(universe) + '_risk_data.pkl','rb') as file2:\n",
    "    risk_data = pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_sets = fac_results.factor_name.to_list()  \n",
    "total_data = factor_data.merge(risk_data, on=['code', 'trade_date'])\n",
    "risk_styles = [i for i in risk_data.columns if i not in ['trade_date','code']]\n",
    "industry_styles = ['Bank','RealEstate','Health','Transportation','Mining',\n",
    "                                 'NonFerMetal','HouseApp','LeiService','MachiEquip','BuildDeco',\n",
    "                                 'CommeTrade','CONMAT','Auto','Textile','FoodBever','Electronics',\n",
    "                                 'Computer','LightIndus','Utilities','Telecom','AgriForest','CHEM',\n",
    "                                 'Media','IronSteel','NonBankFinan','ELECEQP','AERODEF','Conglomerates']\n",
    "\n",
    "ndiff_field = ['trade_date','code','ret'] + risk_styles\n",
    "\n",
    "total_data = total_data.sort_values(by=['trade_date','code'],ascending=True)\n",
    "\n",
    "\n",
    "total_data = total_data.set_index('trade_date'\n",
    "                                 ).loc[total_data.trade_date.unique()[0:100]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_res = []\n",
    "grouped = total_data.groupby(['trade_date'])\n",
    "for k, g in grouped:\n",
    "    f = pd.DataFrame()\n",
    "    for factor_name in factor_sets:\n",
    "        f[factor_name] = se_standardize(se_winsorize(g[factor_name].values)) # 去极值->标准化\n",
    "    for k in ndiff_field:\n",
    "        f[k] = g[k].values\n",
    "    alpha_res.append(f)\n",
    "alpha_data = pd.concat(alpha_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data_list = []\n",
    "for name in factor_sets:\n",
    "    factor_data_list.append({'name':name,'data':alpha_data[name].values})\n",
    "    \n",
    "with multiprocessing.Pool(processes=4) as p:\n",
    "    values_list = p.map(nan_rate, factor_data_list)\n",
    "factor_rate = pd.DataFrame(values_list)\n",
    "factor_rate = factor_rate[factor_rate.rate > 0.65]\n",
    "alpha_data = alpha_data[list(factor_rate.name) + ndiff_field]\n",
    "\n",
    "## 均值处理Nan\n",
    "alpha_res = []\n",
    "grouped = total_data.groupby(['trade_date'])\n",
    "for k, g in grouped:\n",
    "    f = pd.DataFrame()\n",
    "    for factor_name in factor_sets:\n",
    "        factor_data = g[factor_name].values\n",
    "        factor_data[np.isnan(factor_data)] = factor_data[~np.isnan(factor_data)].mean()\n",
    "        f[factor_name] =factor_data\n",
    "    for k in ndiff_field:\n",
    "        f[k] = g[k].values\n",
    "    alpha_res.append(f)\n",
    "standard_data = pd.concat(alpha_res)\n",
    "#移动收益率\n",
    "def shift_ret(data):\n",
    "    data = data.sort_values(by='trade_date',ascending=True)\n",
    "    data['ret'] = data['ret'].shift(-1)\n",
    "    return data.dropna(subset=['ret'])\n",
    "now_data = standard_data.groupby(['code']).apply(shift_ret)\n",
    "\n",
    "standard_data = now_data.set_index('code').reset_index().sort_values(by=['trade_date','code'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:  2.9min remaining:  8.8min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2147483648, -2147483648, -2147483648, 1.0797148283922677, 1.0797148283922677]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   20.5s remaining:  1.0min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   24.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2147483648, -2147483648, -2147483648, 1.0797148283922677, 1.0797148283922677]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   12.3s remaining:   37.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   17.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2147483648, -2147483648, -2147483648, 1.0797148283922677, 1.0797148283922677]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:  3.4min remaining: 10.2min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2147483648, -2147483648, -2147483648, 1.0797148283922677, 1.0797148283922677]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:  3.3min remaining: 10.0min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2147483648, -2147483648, 2.8093538155285027e-05, 1.0797148283922677, 1.0797148283922677]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:  4.3min remaining: 13.0min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2147483648, 2.8093538155285027e-05, 0.0018803728069077107, 1.0797148283922677, 1.0797148283922677]\n"
     ]
    }
   ],
   "source": [
    "gentic = Gentic(population_size=10, tournament_size = 5, \n",
    "                init_depth=(5, 7),\n",
    "                generations=6, n_jobs = 8, stopping_criteria=100, verbose=1,\n",
    "                factor_sets = factor_sets,\n",
    "                fitness=websim_weighted)\n",
    "\n",
    "\n",
    "gentic.train(total_data=standard_data)\n",
    "result = gentic._run_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Source' object has no attribute 'write_png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-56f68bd0134a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_programs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Source' object has no attribute 'write_png'"
     ]
    }
   ],
   "source": [
    "graphviz.Source(result['best_programs'][-1][-1].export_graphviz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fac = calc_factor(result['best_programs'][-2][-9].transform(), standard_data, 'trade_date', 'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformed</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>900953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>900955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>900956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>900957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>603297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>603790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>603810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>300748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>603583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>300749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>601577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>300694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>601162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>300674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>300751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>603220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>601319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>300752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>603187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>300753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            transformed    code\n",
       "trade_date                     \n",
       "2018-08-31          NaN       1\n",
       "2018-08-31          NaN       2\n",
       "2018-08-31          NaN       4\n",
       "2018-08-31          NaN       5\n",
       "2018-08-31          NaN       6\n",
       "2018-08-31          NaN       7\n",
       "2018-08-31          NaN       8\n",
       "2018-08-31          NaN       9\n",
       "2018-08-31          NaN      10\n",
       "2018-08-31          NaN      11\n",
       "2018-08-31          NaN      12\n",
       "2018-08-31          NaN      14\n",
       "2018-08-31          NaN      16\n",
       "2018-08-31          NaN      17\n",
       "2018-08-31          NaN      18\n",
       "2018-08-31          NaN      19\n",
       "2018-08-31          NaN      20\n",
       "2018-08-31          NaN      21\n",
       "2018-08-31          NaN      22\n",
       "2018-08-31          NaN      23\n",
       "2018-08-31          NaN      25\n",
       "2018-08-31          NaN      26\n",
       "2018-08-31          NaN      27\n",
       "2018-08-31          NaN      28\n",
       "2018-08-31          NaN      29\n",
       "2018-08-31          NaN      30\n",
       "2018-08-31          NaN      31\n",
       "2018-08-31          NaN      32\n",
       "2018-08-31          NaN      34\n",
       "2018-08-31          NaN      35\n",
       "...                 ...     ...\n",
       "2018-08-31          NaN  900953\n",
       "2018-08-31          NaN  900955\n",
       "2018-08-31          NaN  900956\n",
       "2018-08-31          NaN  900957\n",
       "2018-09-05          NaN    2935\n",
       "2018-09-10          NaN  603297\n",
       "2018-09-13          NaN  603790\n",
       "2018-09-18          NaN    2938\n",
       "2018-09-18          NaN  603810\n",
       "2018-09-21          NaN    2936\n",
       "2018-09-21          NaN  300748\n",
       "2018-09-21          NaN  603583\n",
       "2018-09-27          NaN    2937\n",
       "2018-09-27          NaN  300749\n",
       "2018-09-27          NaN  601577\n",
       "2018-10-17          NaN  300694\n",
       "2018-10-17          NaN  300760\n",
       "2018-10-22          NaN  601162\n",
       "2018-10-25          NaN    2940\n",
       "2018-10-30          NaN    2939\n",
       "2018-11-07          NaN  300674\n",
       "2018-11-12          NaN  300751\n",
       "2018-11-15          NaN  603220\n",
       "2018-11-20          NaN  601319\n",
       "2018-11-28          NaN    2941\n",
       "2018-12-03          NaN    2943\n",
       "2018-12-03          NaN  300752\n",
       "2018-12-03          NaN  603187\n",
       "2018-12-06          NaN    2942\n",
       "2018-12-14          NaN  300753\n",
       "\n",
       "[3665 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fac[np.isnan(data_fac.transformed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
